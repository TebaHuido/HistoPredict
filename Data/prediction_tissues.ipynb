{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff5e4cc-f97b-46b7-890c-d92eefe71474",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAoACgDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDhN8gKRsGJOGOB3+v4VY2tc27uGG7cAqM3bvg1Gksc7qPLBRX3DceR+HepjPK1pJbKFCQtuYhRyc9civSPSIZVk8tFZTg8KCOnqBipI4GbY8ciNkD5ZOq//W70yKPPl4WXf5gBZT1HbJ9aWJjJM5SRSpU7t47/AJcHpTGSJKm5ImxtYneB93qOPbiio12CTy5MFgv314C8frRQO1xtuxWJsLG8iEkAcnIp8coO5HXC8OzA4yeSM/QZp9nLFZz5A80FiSW4ZfQjsafLtmJkLbIcBjkk4JHOPXrS6isU8mPcoLK65+XPX0qSKKYF258pVK+YcYI6kD34pFWLAGM7QzEehPTBzTwDFKI5g0ZUqSF/Pv1pjtdCQXTxq0mMgHb26HgDpRTCEWRRG6SRKQx65xnp7GigEh21pFRlRlZAT8pJyfb+dIt26W3khQFOTtddwz9D0PvRRTJJF5sQo27yQ3zggYweB6YNSD7KZcyO8bMM5+8Afz78+tFFSXYSOCMyTmeSIsV2pjPX17YH+NFFFANH/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=40x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Cargar la imagen\n",
    "img = Image.open('./inputTensor/Glandula_mamaria/recorte_1.png')\n",
    "\n",
    "# Mostrar la imagen\n",
    "img.show()\n",
    "\n",
    "# (Opcional) Convertir a otro formato (por ejemplo, PNG)\n",
    "# img.save('ruta_a_tu_imagen.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e5bb5e-6916-4378-836c-5e2348e356ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 771 images belonging to 5 classes.\n",
      "Found 192 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.2443 - loss: 2.3687 - val_accuracy: 0.5990 - val_loss: 1.1519\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.5903 - loss: 1.0792 - val_accuracy: 0.7135 - val_loss: 0.8894\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7103 - loss: 0.7177 - val_accuracy: 0.6927 - val_loss: 0.7792\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7514 - loss: 0.7221 - val_accuracy: 0.6823 - val_loss: 0.7859\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7991 - loss: 0.5491 - val_accuracy: 0.8229 - val_loss: 0.5305\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.8284 - loss: 0.4419 - val_accuracy: 0.7812 - val_loss: 0.6200\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8169 - loss: 0.5071 - val_accuracy: 0.7812 - val_loss: 0.6457\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8342 - loss: 0.4675 - val_accuracy: 0.8594 - val_loss: 0.3879\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8910 - loss: 0.3163 - val_accuracy: 0.8490 - val_loss: 0.3876\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8859 - loss: 0.3115 - val_accuracy: 0.7969 - val_loss: 0.5174\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8108 - loss: 0.5169\n",
      "Pérdida: 0.5174, Precisión: 0.7969\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Configuración\n",
    "input_dir = './inputTensor/'  # Directorio de las imágenes\n",
    "img_height, img_width = 224, 224  # Tamaño al que se redimensionan las imágenes\n",
    "batch_size = 32\n",
    "\n",
    "# Generadores de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,          # Normalizar valores entre 0 y 1\n",
    "    validation_split=0.2      # 20% para validación\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    input_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    input_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Construcción del modelo CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(train_data.num_classes, activation='softmax')  # N clases según carpetas\n",
    "])\n",
    "\n",
    "# Compilación\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "model.save('modelo_tejidos.keras')\n",
    "\n",
    "# Evaluar en datos de validación\n",
    "val_loss, val_acc = model.evaluate(val_data)\n",
    "print(f'Pérdida: {val_loss:.4f}, Precisión: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3961757-f415-4b83-b5b0-94225e4e3aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "La imagen pertenece a la clase: Glandula_mamaria\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "model = tf.keras.models.load_model('modelo_tejidos.keras')\n",
    "\n",
    "# Ruta de la imagen a predecir\n",
    "image_path = './inputTensor/Glandula_mamaria/recorte_1.png'\n",
    "\n",
    "# Preprocesar la imagen\n",
    "img_height, img_width = 224, 224  # Tamaño de entrada del modelo\n",
    "img = load_img(image_path, target_size=(img_height, img_width))  # Cargar y redimensionar\n",
    "img_array = img_to_array(img)  # Convertir a array\n",
    "img_array = img_array / 255.0  # Normalizar\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Añadir dimensión de lote\n",
    "\n",
    "# Hacer la predicción\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Obtener la clase predicha\n",
    "class_indices = train_data.class_indices  # Diccionario clase: índice (del generador)\n",
    "class_labels = {v: k for k, v in class_indices.items()}  # Invertir diccionario\n",
    "predicted_class = class_labels[np.argmax(predictions)]\n",
    "\n",
    "print(f'La imagen pertenece a la clase: {predicted_class}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
